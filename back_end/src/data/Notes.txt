
-> Only full text metadata gets saved to the database
Actual text gets saved as JSON files.
-> We're not at the stage where we are ready to process full texts yet

-> Graph will need to be updated periodically when new data is added

-> Dynamic taxonomy expansion based on discovered
interventions

-> Integration with medical ontologies (MeSH,
SNOMED)

-> human-in-the-loop validation

-> Consider PostgreSQL for better concurrency

-> Finalize the dual LLM approach (voting etc)

-> Check if the LLMs consensus handles captioning overlap 'ibs' 'IBS' 


LLm:

-> Consider fine tuning

-> In config.py why is: self.intervention_batch_size = 5
    and self.max_papers_per_condition = 100 ?

Quality assurance workflow: first model extracts → validation catches issues 
→ second model verifies problematic extractions → humans review what both 
models couldn't handle.
-> This might not be the best practice. Check Notion AI folder for practices like voting.

Hybrid Strategy:
Process ALL papers with abstracts (baseline data)
ENHANCE the subset with full text when available. (Use powerful models)
Two-tier relationship confidence scoring (abstract only vs full text)








